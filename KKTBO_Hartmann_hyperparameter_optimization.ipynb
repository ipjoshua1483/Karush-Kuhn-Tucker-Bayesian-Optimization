{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBKc26DIkx6i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a164db03-735e-466d-fbd4-09533622fe56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.11-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch) (1.2.2)\n",
            "Collecting linear-operator>=0.5.0 (from gpytorch)\n",
            "  Downloading linear_operator-0.5.0-py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.0/173.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (1.10.1)\n",
            "Collecting jaxtyping>=0.2.9 (from linear-operator>=0.5.0->gpytorch)\n",
            "  Downloading jaxtyping-0.2.20-py3-none-any.whl (24 kB)\n",
            "Collecting typeguard~=2.13.3 (from linear-operator>=0.5.0->gpytorch)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.22.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.9->linear-operator>=0.5.0->gpytorch) (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->linear-operator>=0.5.0->gpytorch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.3.0)\n",
            "Installing collected packages: typeguard, jaxtyping, linear-operator, gpytorch\n",
            "Successfully installed gpytorch-1.11 jaxtyping-0.2.20 linear-operator-0.5.0 typeguard-2.13.3\n",
            "Collecting botorch\n",
            "  Downloading botorch-0.8.5-py3-none-any.whl (530 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.3/530.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from botorch) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from botorch) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.10/dist-packages (from botorch) (2.0.1+cu118)\n",
            "Collecting pyro-ppl>=1.8.4 (from botorch)\n",
            "  Downloading pyro_ppl-1.8.5-py3-none-any.whl (732 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.5/732.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpytorch==1.10 (from botorch)\n",
            "  Downloading gpytorch-1.10-py3-none-any.whl (255 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting linear-operator==0.4.0 (from botorch)\n",
            "  Downloading linear_operator-0.4.0-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.7/156.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch==1.10->botorch) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.3.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->botorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12->botorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12->botorch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12->botorch) (2.1.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch==1.10->botorch) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch==1.10->botorch) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12->botorch) (1.3.0)\n",
            "Installing collected packages: pyro-api, linear-operator, pyro-ppl, gpytorch, botorch\n",
            "  Attempting uninstall: linear-operator\n",
            "    Found existing installation: linear-operator 0.5.0\n",
            "    Uninstalling linear-operator-0.5.0:\n",
            "      Successfully uninstalled linear-operator-0.5.0\n",
            "  Attempting uninstall: gpytorch\n",
            "    Found existing installation: gpytorch 1.11\n",
            "    Uninstalling gpytorch-1.11:\n",
            "      Successfully uninstalled gpytorch-1.11\n",
            "Successfully installed botorch-0.8.5 gpytorch-1.10 linear-operator-0.4.0 pyro-api-0.1.2 pyro-ppl-1.8.5\n"
          ]
        }
      ],
      "source": [
        "!pip install gpytorch\n",
        "!pip install botorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.quasirandom import SobolEngine\n",
        "\n",
        "from botorch.optim import optimize_acqf\n",
        "from botorch.models.gpytorch import GPyTorchModel\n",
        "from botorch.models.model import ModelList\n",
        "\n",
        "from botorch.test_functions import Branin\n",
        "from botorch.test_functions import Hartmann\n",
        "from botorch.test_functions import Cosine8"
      ],
      "metadata": {
        "id": "O7OIriqHftnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tkwargs = {\n",
        "    \"device\": torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    \"dtype\": torch.double,\n",
        "}"
      ],
      "metadata": {
        "id": "7O6e4Tgrg6sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta_mean_list = [1.0]\n",
        "beta_constraint_list = [2.0, 2.5, 3.0]\n",
        "penalty_list = [10]\n",
        "#color_list = ['b', 'g', 'r', 'c', 'm', 'k']\n",
        "#penalty_weight = 10\n",
        "BO_iter = 50\n",
        "num_restarts = 10\n",
        "raw_samples = 1024\n",
        "maxiter = 500\n",
        "GP_iter = 200\n",
        "learning_rate = 0.1\n",
        "n_init = 10"
      ],
      "metadata": {
        "id": "JzZ0WR1DfzNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#objective info\n",
        "dim_list= 6\n",
        "name_list= \"Hartmann\"\n",
        "objective_list = -3.32237\n",
        "plot_bounds = [-4, 0]\n",
        "negate_list = -1.0"
      ],
      "metadata": {
        "id": "q9sHYR65f03m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Branin\n",
        "hartmann = Hartmann(dim = 6, negate = True).to(**tkwargs)\n",
        "\n",
        "def objective1(x):\n",
        "  #lb, ub = branin.bounds\n",
        "  #return branin(lb + (ub - lb) * x[..., :2])\n",
        "  return hartmann(x)"
      ],
      "metadata": {
        "id": "mT-wxjiif9B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "objective = [objective1]"
      ],
      "metadata": {
        "id": "LOMx0CQUf-qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_grad(x, objective):\n",
        "  num_points, dimensions = x.shape\n",
        "  epsilon = 0.01\n",
        "  grad = torch.zeros(num_points, dimensions)\n",
        "  for i in range(dimensions):\n",
        "    x_upper = x.clone()\n",
        "    x_upper[:, i] += epsilon\n",
        "    x_lower = x.clone()\n",
        "    x_lower[:, i] -= epsilon\n",
        "    grad[:, i] = (objective(x_upper) - objective(x_lower)) / (2 * epsilon)\n",
        "  return grad"
      ],
      "metadata": {
        "id": "gNr7DYrcgA3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gpytorch\n",
        "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
        "from gpytorch.likelihoods.gaussian_likelihood import GaussianLikelihood\n",
        "from botorch.models import ModelListGP\n",
        "from botorch.models.higher_order_gp import FlattenedStandardize\n",
        "from botorch.models.transforms import Normalize, Standardize\n",
        "from botorch.models import HigherOrderGP, SingleTaskGP\n",
        "from gpytorch.constraints import Interval\n",
        "from botorch.optim.fit import fit_gpytorch_mll_torch\n",
        "from botorch import fit_gpytorch_model\n",
        "\n",
        "# train model function\n",
        "\n",
        "def train_single_model(X, Y, nu=1.5, noiseless_obs=True):\n",
        "  # make sure training data has the right dimension\n",
        "  if Y.ndim == 1:\n",
        "      Y = Y.unsqueeze(-1)\n",
        "  # outcome transform\n",
        "  standardize = Standardize(m=Y.shape[-1], batch_shape=Y.shape[:-2])\n",
        "  outcome_transform = standardize\n",
        "  # covariance module\n",
        "  covar_module = ScaleKernel(MaternKernel(nu=nu, ard_num_dims=X.shape[-1]))\n",
        "  # likelihood\n",
        "  if noiseless_obs:\n",
        "      _, aug_batch_shape = SingleTaskGP.get_batch_dimensions(\n",
        "          train_X=X,\n",
        "          train_Y=Y,\n",
        "      )\n",
        "      likelihood = GaussianLikelihood(\n",
        "          batch_shape=aug_batch_shape,\n",
        "          noise_constraint=Interval(lower_bound=1e-4, upper_bound=1e-3),\n",
        "      )\n",
        "  else:\n",
        "      likelihood = None\n",
        "  # define the model\n",
        "  model = SingleTaskGP(\n",
        "      train_X=X,\n",
        "      train_Y=Y,\n",
        "      covar_module=covar_module,\n",
        "      likelihood=likelihood,\n",
        "      outcome_transform=outcome_transform,\n",
        "  )\n",
        "\n",
        "  # call the training procedure\n",
        "  model.outcome_transform.eval()\n",
        "  mll = gpytorch.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "  fit_gpytorch_model(mll)\n",
        "  # put in eval mode\n",
        "  model.eval()\n",
        "  # return the model\n",
        "  return model\n",
        "\n",
        "def train_model(X, Y, nu=2.5, noiseless_obs=True):\n",
        "  model_list = []\n",
        "  noutput = Y.shape[1]\n",
        "  for i in range(noutput):\n",
        "    model_i = train_single_model(X, Y[:,i], nu=nu, noiseless_obs=noiseless_obs)\n",
        "    model_list += [model_i]\n",
        "  #model = ModelListGP(*model_list)\n",
        "  return model_list\n",
        "\n",
        "def get_posterior_stats(model, point):\n",
        "  \"\"\"Get the mean and standard deviation of the model's posterior at a given point.\"\"\"\n",
        "  #model_grad = self.model_all[1:]\n",
        "  #model_grad[dim].eval()\n",
        "  model.eval()\n",
        "  #cur_points.requires_grad_ = True\n",
        "  with torch.enable_grad():\n",
        "    posterior = model.posterior(point)\n",
        "    mean = posterior.mean\n",
        "    std_dev = posterior.variance.sqrt()\n",
        "  return mean, std_dev"
      ],
      "metadata": {
        "id": "0EoFQ2dFgEk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from botorch.acquisition import AnalyticAcquisitionFunction\n",
        "from botorch.models.model import Model\n",
        "from botorch.utils import t_batch_mode_transform\n",
        "from torch import Tensor\n",
        "\n",
        "class ConstrainedUCB(AnalyticAcquisitionFunction):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: ModelList,\n",
        "        beta_mean: float,\n",
        "        beta_constraint: float,\n",
        "        penalty_weight: int,\n",
        "    ) -> None:\n",
        "        super(AnalyticAcquisitionFunction, self).__init__(model)\n",
        "        self.model_list_new = model_list_new\n",
        "        self.beta_mean = beta_mean\n",
        "        self.beta_constraint = beta_constraint\n",
        "        self.penalty_weight = penalty_weight\n",
        "        #self.register_buffer(\"beta\", torch.as_tensor(beta))\n",
        "        #self.register_buffer(\"weights\", torch.as_tensor(weights))\n",
        "\n",
        "    @t_batch_mode_transform(expected_q=1)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        means, std_devs = get_posterior_stats(self.model_list_new, x) #b x q x d (q=1)\n",
        "        means = means.squeeze() #b x d (removes q)\n",
        "        std_devs = std_devs.squeeze() #b x d\n",
        "        UCB = means[:, 0] + self.beta_mean * std_devs[:, 0] # b\n",
        "        constraint_violation = torch.abs(means[:, 1:]) - self.beta_constraint * std_devs[:, 1:] #b x (d - 1) -> first dimension mean removed\n",
        "        constraint_violation = constraint_violation.unsqueeze(-1) #b x (d-1) x 1\n",
        "        zero = torch.zeros(constraint_violation.shape) #b x (d-1) x 1\n",
        "        constraint_penalty = torch.sum(torch.max(constraint_violation, zero) ** 2, dim = 1).squeeze(-1) #b\n",
        "        result = UCB - self.penalty_weight * constraint_penalty # b\n",
        "        return result"
      ],
      "metadata": {
        "id": "2SItmZ7ggKPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create 3D torch tensor to store Y values (#trials to avg x #test problems x #BO methods x #BO iterations)\n",
        "num_avg_trials = 1\n",
        "num_penalty = len(penalty_list)\n",
        "num_beta_mean = len(beta_mean_list)\n",
        "num_beta_constraint = len(beta_constraint_list)\n",
        "\n",
        "Y_all = torch.zeros((num_avg_trials, num_penalty, num_beta_mean, num_beta_constraint, n_init + BO_iter))"
      ],
      "metadata": {
        "id": "llueTGm2hG0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_AF(acq_func, bounds, q = 1, num_restarts = num_restarts, raw_samples = raw_samples, maxiter = maxiter):\n",
        "  candidate, acq_value = optimize_acqf(\n",
        "            acq_function = acq_func,\n",
        "            bounds = bounds,\n",
        "            #torch.cat((torch.zeros(1, dim), torch.ones(1, dim))).to(**tkwargs),\n",
        "            #batch_limit = 1,\n",
        "            q = q,  # number of candidates to generate (1 for single-point optimization)\n",
        "            num_restarts = num_restarts,  # number of starting points for multistart optimization\n",
        "            raw_samples = raw_samples,  # number of samples for initialization heuristic\n",
        "            options = {\"maxiter\": maxiter},\n",
        "            sequential = True,  # use sequential optimization\n",
        "  )\n",
        "  return candidate, acq_value"
      ],
      "metadata": {
        "id": "tH98M_lTuF1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#perform trials separately due to errors"
      ],
      "metadata": {
        "id": "iq7s7_reT2H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from botorch.acquisition import UpperConfidenceBound\n",
        "from botorch.acquisition import ExpectedImprovement\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import botorch.settings\n",
        "suppress_botorch_warnings = True\n",
        "\n",
        "for a in range(num_avg_trials):\n",
        "  for i, p in enumerate(penalty_list):\n",
        "    for j, beta_mean in enumerate(beta_mean_list):\n",
        "      for k, beta_constraint in enumerate(beta_constraint_list):\n",
        "        bounds = torch.cat((torch.zeros(1, dim_list), torch.ones(1, dim_list))).to(**tkwargs)\n",
        "\n",
        "        X = SobolEngine(dimension=dim_list, scramble=True, seed=0).draw(n_init).to(**tkwargs)\n",
        "        Y = objective[0](X).unsqueeze(-1)\n",
        "        Y_grad = compute_grad(X, objective[0])\n",
        "        X_KKT = X\n",
        "        Y_KKT = torch.hstack((Y, Y_grad))\n",
        "\n",
        "        for l in range(BO_iter):\n",
        "          #print general info\n",
        "          print(f\"\\n Trial: {a + 1}, Iteration: {l + 1 + n_init}, Penalty: {p}, Beta mean: {beta_mean}, Beta constraint: {beta_constraint}\")\n",
        "\n",
        "          #KKT\n",
        "          model_list = train_model(X_KKT, Y_KKT, nu = 2.5)\n",
        "          model_list_new = ModelList(*model_list)\n",
        "          acq_func = ConstrainedUCB(model_list_new, beta_mean, beta_constraint, p)\n",
        "          candidate, acq_value = optimize_AF(acq_func, bounds)\n",
        "\n",
        "          Y_mean_new = objective[0](candidate)\n",
        "          Y_grad_new = compute_grad(candidate, objective[0]).squeeze()\n",
        "          Y_new = torch.hstack((Y_mean_new, Y_grad_new))\n",
        "          X_KKT = torch.vstack((X_KKT, candidate))\n",
        "          Y_KKT = torch.vstack((Y_KKT, Y_new))\n",
        "          Y_grad_GP = get_posterior_stats(model_list_new, candidate)[0][0, 1:]\n",
        "          print(\"Best value: \", negate_list * Y_KKT[:, 0].max().item(), \", X: \", candidate, \"AF: \", acq_value, \", Y: \", negate_list * Y_mean_new.item(), \", Y grad GP: \", negate_list * Y_grad_GP, \", Y grad query: \", negate_list * Y_grad_new)\n",
        "\n",
        "          if len(Y_KKT) == n_init + BO_iter:\n",
        "            Y_all[a, i, j, k] = Y_KKT[:, 0].reshape(n_init + BO_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISdZiANAhQ35",
        "outputId": "23055114-b8ef-4c5e-d08d-52276022af9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Trial: 1, Iteration: 11, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.9445, 0.9691, 0.9956, 0.1160, 0.8793, 0.8538]], dtype=torch.float64) AF:  tensor(1.3604, dtype=torch.float64) , Y:  -0.0002604075303723283 , Y grad GP:  tensor([ 0.6153, -0.0962, -0.0789, -1.2053,  0.0079,  1.1868],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0003,  0.0025,  0.0013, -0.0002,  0.0036, -0.0006])\n",
            "\n",
            " Trial: 1, Iteration: 12, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.8305, 0.0336, 0.9731, 0.5616, 0.6243, 0.1327]], dtype=torch.float64) AF:  tensor(1.2297, dtype=torch.float64) , Y:  -0.004870071807769201 , Y grad GP:  tensor([-0.1551, -0.4026, -0.1126, -1.6622, -0.1794, -0.0715],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0219, -0.0088,  0.0097,  0.0243,  0.0484, -0.0371])\n",
            "\n",
            " Trial: 1, Iteration: 13, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.1009, 0.5231, 0.9056, 0.6875, 0.9005, 0.4995]], dtype=torch.float64) AF:  tensor(1.3040, dtype=torch.float64) , Y:  -0.026771660825462267 , Y grad GP:  tensor([-2.6776, -0.0341,  0.1599,  1.3832,  0.4065,  1.4414],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.1128, -0.0212,  0.1942,  0.1026,  0.0159,  0.1018])\n",
            "\n",
            " Trial: 1, Iteration: 14, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.16420343697261 , X:  tensor([[1.0000, 0.8520, 0.8164, 0.0453, 0.7250, 0.0734]], dtype=torch.float64) AF:  tensor(1.2505, dtype=torch.float64) , Y:  -0.0005517825525844938 , Y grad GP:  tensor([ 0.7029, -1.0133,  0.0284, -0.1108,  0.1173,  2.2124],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0096,  0.0003,  0.0002, -0.0052,  0.0015, -0.0006])\n",
            "\n",
            " Trial: 1, Iteration: 15, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.1674, 0.4029, 0.1698, 0.7239, 0.3396, 0.1110]], dtype=torch.float64) AF:  tensor(1.2830, dtype=torch.float64) , Y:  -0.16920905815949086 , Y grad GP:  tensor([-0.3603, -0.1916,  0.0788,  0.7746,  0.1666,  1.7393],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-1.1401, -1.0239, -0.0430,  0.6683,  0.0375,  0.0286])\n",
            "\n",
            " Trial: 1, Iteration: 16, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.2096, 0.8926, 0.8758, 0.0678, 0.7416, 0.1398]], dtype=torch.float64) AF:  tensor(1.2559, dtype=torch.float64) , Y:  -0.11446083594069159 , Y grad GP:  tensor([ 0.2954, -0.2119, -0.0820, -0.3962, -0.0164,  0.1401],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.6986,  0.0498,  0.0748, -1.0849,  0.0220,  0.2496])\n",
            "\n",
            " Trial: 1, Iteration: 17, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.0385, 0.9055, 0.3692, 0.6841, 0.0674, 0.9792]], dtype=torch.float64) AF:  tensor(1.2511, dtype=torch.float64) , Y:  -0.017894233363696513 , Y grad GP:  tensor([-3.3499,  0.2591,  0.0093, -0.1277,  0.1359, -0.2844],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.0194,  0.1058, -0.0574,  0.1125, -0.1109,  0.0772])\n",
            "\n",
            " Trial: 1, Iteration: 18, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.16420343697261 , X:  tensor([[1.0000, 0.7982, 1.0000, 0.2765, 0.9124, 0.2934]], dtype=torch.float64) AF:  tensor(0.7257, dtype=torch.float64) , Y:  -0.001171517266728283 , Y grad GP:  tensor([-1.9023, -0.7723, -0.3892, -0.1276,  0.0767,  1.3955],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0233, -0.0014,  0.0001, -0.0067,  0.0009,  0.0079])\n",
            "\n",
            " Trial: 1, Iteration: 19, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.1948, 0.8899, 0.4308, 0.8556, 0.1668, 0.0778]], dtype=torch.float64) AF:  tensor(1.0911, dtype=torch.float64) , Y:  -0.6657690461667415 , Y grad GP:  tensor([ 7.3515e-02, -5.8937e-01, -2.2669e-03, -7.8150e-04,  2.0130e-02,\n",
            "         2.1133e+00], dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-4.7346e+00,  8.2279e-02, -3.2420e-02,  3.7479e+00,  2.3189e-03,\n",
            "         7.2359e-01])\n",
            "\n",
            " Trial: 1, Iteration: 20, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.1520, 0.7457, 0.0000, 0.4698, 0.9541, 0.2443]], dtype=torch.float64) AF:  tensor(0.9496, dtype=torch.float64) , Y:  -0.41238965607296885 , Y grad GP:  tensor([-2.6645, -0.7187, -0.4462, -0.7984,  0.2654,  0.9283],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.5378, -0.9018, -0.0426, -0.8584,  0.0718,  2.3739])\n",
            "\n",
            " Trial: 1, Iteration: 21, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.9325007859252104 , X:  tensor([[0.3460, 0.7984, 0.0000, 0.3913, 0.1519, 0.0000]], dtype=torch.float64) AF:  tensor(0.7174, dtype=torch.float64) , Y:  -1.9325007859252104 , Y grad GP:  tensor([-2.3900, -0.7961, -0.0495, -0.8721,  0.2311,  1.5219],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.8267, -2.5543, -0.1793, -7.0142, -0.0315, -2.1475])\n",
            "\n",
            " Trial: 1, Iteration: 22, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.9325007859252104 , X:  tensor([[1.0000, 0.6383, 1.0000, 0.4917, 0.5459, 0.1318]], dtype=torch.float64) AF:  tensor(1.1061, dtype=torch.float64) , Y:  -0.006628767884605565 , Y grad GP:  tensor([-1.8390, -0.7944, -0.1263, -0.7169, -0.0516,  1.2898],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0916, -0.0057,  0.0061,  0.0047,  0.0228, -0.0133])\n",
            "\n",
            " Trial: 1, Iteration: 23, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.9325007859252104 , X:  tensor([[3.4014e-01, 8.3050e-01, 5.8276e-01, 4.9570e-01, 1.2271e-05, 7.8183e-01]],\n",
            "       dtype=torch.float64) AF:  tensor(2.1211, dtype=torch.float64) , Y:  -0.11563781124030964 , Y grad GP:  tensor([-1.1531,  0.0907, -0.2194, -0.4631,  0.0854, -0.2595],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.1101,  0.6584, -0.2333,  0.3139, -0.7445, -0.0201])\n",
            "\n",
            " Trial: 1, Iteration: 24, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.9325007859252104 , X:  tensor([[0.3649, 0.7511, 1.0000, 0.2726, 0.7857, 0.0000]], dtype=torch.float64) AF:  tensor(1.7014, dtype=torch.float64) , Y:  -1.0209331028168436 , Y grad GP:  tensor([-1.0503, -0.8145, -0.1737, -2.3629, -0.0062,  0.6132],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-1.3768, -2.1459,  0.0190, -6.1545,  0.1416, -1.0928])\n",
            "\n",
            " Trial: 1, Iteration: 25, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.9325007859252104 , X:  tensor([[0.1255, 0.6859, 1.0000, 0.3706, 0.0000, 0.0000]], dtype=torch.float64) AF:  tensor(1.3594, dtype=torch.float64) , Y:  -0.4058437868639378 , Y grad GP:  tensor([-1.2310, -1.2193,  0.0119, -1.9022,  0.1691, -1.5850],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.8249, -1.2566,  0.0144, -1.6343, -0.0389, -0.4614])\n",
            "\n",
            " Trial: 1, Iteration: 26, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.9325007859252104 , X:  tensor([[0.3208, 1.0000, 0.1704, 0.4769, 0.0000, 0.2709]], dtype=torch.float64) AF:  tensor(1.2497, dtype=torch.float64) , Y:  -1.0649549626424497 , Y grad GP:  tensor([-3.0145, -0.7899, -0.0100, -2.5919, -0.0649,  0.8357],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-2.9993,  2.0338, -0.0857, -2.0194, -0.1172,  6.8171])\n",
            "\n",
            " Trial: 1, Iteration: 27, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -1.9325007859252104 , X:  tensor([[0.5174, 1.0000, 0.0000, 0.3515, 0.0000, 0.0000]], dtype=torch.float64) AF:  tensor(1.1677, dtype=torch.float64) , Y:  -1.3258679739762136 , Y grad GP:  tensor([-2.2831, -0.4143, -0.1542, -3.0946, -0.0049, -0.7237],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 5.0722,  2.4879, -0.1168, -5.8981, -0.0378, -1.4207])\n",
            "\n",
            " Trial: 1, Iteration: 28, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -2.9750955015516007 , X:  tensor([[0.3670, 0.9000, 0.1869, 0.5902, 0.2241, 0.0000]], dtype=torch.float64) AF:  tensor(1.8803, dtype=torch.float64) , Y:  -2.9750955015516007 , Y grad GP:  tensor([-2.7346,  0.0091, -0.0920, -2.3248,  0.1015, -1.2563],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.7945,  0.8379, -0.2076,  0.9696,  0.0575, -3.2075])\n",
            "\n",
            " Trial: 1, Iteration: 29, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.1565407199222233 , X:  tensor([[0.4083, 0.8882, 0.5936, 0.5909, 0.3633, 0.0525]], dtype=torch.float64) AF:  tensor(2.9398, dtype=torch.float64) , Y:  -3.1565407199222233 , Y grad GP:  tensor([-1.7556,  0.5404, -0.0319,  0.8669,  0.1841, -1.3323],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.4064,  0.3165, -0.0799,  1.0917,  0.1702,  1.1819])\n",
            "\n",
            " Trial: 1, Iteration: 30, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.1565407199222233 , X:  tensor([[0.4684, 0.8407, 1.0000, 0.6706, 1.0000, 0.0050]], dtype=torch.float64) AF:  tensor(3.0628, dtype=torch.float64) , Y:  -2.4394006852998906 , Y grad GP:  tensor([ 2.6013, -1.0741, -0.1220,  2.0451,  0.2535,  0.9333],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 5.2754, -1.6420,  0.0315,  4.6945,  0.4347, -2.2556])\n",
            "\n",
            " Trial: 1, Iteration: 31, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.4025, 0.8774, 0.9207, 0.5577, 0.0991, 0.0447]], dtype=torch.float64) AF:  tensor(3.2094, dtype=torch.float64) , Y:  -3.190577241261887 , Y grad GP:  tensor([ 0.2314, -0.1358, -0.0469, -0.4975,  0.0982,  0.6114],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.2366, -0.2620,  0.0221, -1.0451, -0.0252,  0.5635])\n",
            "\n",
            " Trial: 1, Iteration: 32, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.5690, 0.9075, 0.2718, 0.5795, 1.0000, 0.1701]], dtype=torch.float64) AF:  tensor(1.9936, dtype=torch.float64) , Y:  -1.430661118370786 , Y grad GP:  tensor([ 3.7321,  0.9757, -0.0980,  0.7240,  0.4159,  2.7668],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 7.9839,  0.5674, -0.0913,  0.1517,  0.2552,  5.2757])\n",
            "\n",
            " Trial: 1, Iteration: 33, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.4134, 0.7022, 0.0127, 0.6277, 0.5063, 0.1571]], dtype=torch.float64) AF:  tensor(2.3199, dtype=torch.float64) , Y:  -1.876541689068017 , Y grad GP:  tensor([ 1.0651, -1.5495, -0.0242,  2.1052,  0.1114,  1.0611],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.5657, -5.3150, -0.1789,  2.0911,  0.2519,  6.0715])\n",
            "\n",
            " Trial: 1, Iteration: 34, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.4181, 0.5094, 1.0000, 0.6065, 0.2186, 0.0035]], dtype=torch.float64) AF:  tensor(1.4753, dtype=torch.float64) , Y:  -1.0235774078154949 , Y grad GP:  tensor([ 0.0656, -1.9536,  0.0703,  0.6218,  0.0472, -2.1907],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 4.6985e-01, -6.0451e+00,  3.2321e-02,  7.0607e-01, -1.5852e-03,\n",
            "        -1.0685e+00])\n",
            "\n",
            " Trial: 1, Iteration: 35, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.4595, 1.0000, 0.5001, 0.8821, 0.2844, 0.0519]], dtype=torch.float64) AF:  tensor(1.6223, dtype=torch.float64) , Y:  -1.0434880998441278 , Y grad GP:  tensor([ 3.3558,  2.0525, -0.0205,  3.3776,  0.1147,  0.2999],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.9408,  1.9570, -0.0391,  6.4230,  0.0360,  0.3981])\n",
            "\n",
            " Trial: 1, Iteration: 36, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.6867, 0.8193, 0.7441, 0.5998, 0.2296, 0.0000]], dtype=torch.float64) AF:  tensor(1.2178, dtype=torch.float64) , Y:  -0.7811284653504164 , Y grad GP:  tensor([ 3.9639, -1.3631, -0.0454,  0.4949,  0.3267, -1.0096],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 7.4715e+00, -7.7774e-01, -6.1896e-03,  4.1349e-01,  1.2105e-02,\n",
            "        -8.5724e-01])\n",
            "\n",
            " Trial: 1, Iteration: 37, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.4286, 0.8617, 0.0377, 0.5939, 0.5528, 0.3660]], dtype=torch.float64) AF:  tensor(1.2839, dtype=torch.float64) , Y:  -0.6868179840274637 , Y grad GP:  tensor([ 2.1417, -0.4259, -0.0218,  1.3414,  0.1216,  3.2054],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.5677, -0.0956, -0.0856,  0.4147,  0.2722,  5.9490])\n",
            "\n",
            " Trial: 1, Iteration: 38, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.7197, 1.0000, 0.8202, 0.8744, 0.1245, 0.0000]], dtype=torch.float64) AF:  tensor(0.8977, dtype=torch.float64) , Y:  -0.21143766505534578 , Y grad GP:  tensor([ 4.2820,  0.9449, -0.0057,  3.4767, -0.0871, -0.7635],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 2.2644e+00,  3.9638e-01, -1.0301e-03,  1.2686e+00,  3.8351e-04,\n",
            "        -2.2568e-01])\n",
            "\n",
            " Trial: 1, Iteration: 39, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[1.0000, 0.0000, 0.0037, 0.0000, 0.1139, 0.7503]], dtype=torch.float64) AF:  tensor(0.8027, dtype=torch.float64) , Y:  -0.08659259893180404 , Y grad GP:  tensor([ 1.2420,  0.1627, -0.1326, -1.1998, -0.2373, -0.2694],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.3976, -0.0879, -0.1026, -0.4991, -0.5612,  0.1181])\n",
            "\n",
            " Trial: 1, Iteration: 40, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.0802, 1.0000, 0.3895, 0.5528, 0.5813, 0.0000]], dtype=torch.float64) AF:  tensor(1.0793, dtype=torch.float64) , Y:  -0.453829306507716 , Y grad GP:  tensor([-3.9163,  0.8592, -0.0687,  0.3012,  0.1302, -1.3649],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-4.9840,  0.8587, -0.0305, -0.1835,  0.0493, -0.5046])\n",
            "\n",
            " Trial: 1, Iteration: 41, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.5099, 0.3820, 0.4750, 0.9218, 0.5241, 0.0453]], dtype=torch.float64) AF:  tensor(0.8018, dtype=torch.float64) , Y:  -0.10539742492511725 , Y grad GP:  tensor([ 1.9527, -2.5118, -0.0612,  2.1418,  0.0382,  0.5061],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.3784, -0.8302, -0.0061,  0.7359,  0.0130,  0.0066])\n",
            "\n",
            " Trial: 1, Iteration: 42, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.7571, 0.2859, 0.6830, 0.0000, 0.9619, 0.5368]], dtype=torch.float64) AF:  tensor(0.7648, dtype=torch.float64) , Y:  -0.014205941221037532 , Y grad GP:  tensor([ 1.2089,  0.1689, -0.1273, -1.0843, -0.1889, -0.3064],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.1746,  0.0094,  0.0591, -0.0029,  0.0132, -0.0128])\n",
            "\n",
            " Trial: 1, Iteration: 43, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.5595, 0.9551, 0.6177, 0.1811, 0.7178, 0.1422]], dtype=torch.float64) AF:  tensor(0.8490, dtype=torch.float64) , Y:  -0.3644790218522781 , Y grad GP:  tensor([ 3.2576,  1.2602,  0.0233, -2.9116,  0.1595,  1.5700],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.9270e+00,  4.4125e-01,  5.4437e-04, -2.8215e+00,  5.7239e-02,\n",
            "         1.0062e+00])\n",
            "\n",
            " Trial: 1, Iteration: 44, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[1.0000, 0.2783, 0.1437, 0.2981, 0.8578, 0.6181]], dtype=torch.float64) AF:  tensor(0.7767, dtype=torch.float64) , Y:  -0.002470597310122169 , Y grad GP:  tensor([ 1.0003,  0.2494, -0.1107, -0.9094, -0.2862, -0.5355],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0116,  0.0023, -0.0020,  0.0005,  0.0462, -0.0018])\n",
            "\n",
            " Trial: 1, Iteration: 45, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.3370, 0.8587, 0.5931, 0.9998, 0.1447, 0.3424]], dtype=torch.float64) AF:  tensor(0.7754, dtype=torch.float64) , Y:  -0.1336114305764903 , Y grad GP:  tensor([-1.6395, -0.0163, -0.0333,  3.1027, -0.1515,  3.3382],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.2955, -0.0396, -0.0024,  1.1385, -0.0065,  1.1058])\n",
            "\n",
            " Trial: 1, Iteration: 46, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.1814, 1.0000, 0.3825, 0.2841, 0.9310, 0.1732]], dtype=torch.float64) AF:  tensor(0.7705, dtype=torch.float64) , Y:  -0.39250657224033797 , Y grad GP:  tensor([-2.7302,  0.9092, -0.0385, -2.7070,  0.0934,  2.1054],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-2.8570,  0.7792, -0.1016, -2.1692,  0.0680,  1.3361])\n",
            "\n",
            " Trial: 1, Iteration: 47, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.5131, 0.7671, 0.6208, 0.9962, 0.3226, 0.0000]], dtype=torch.float64) AF:  tensor(0.8216, dtype=torch.float64) , Y:  -0.3862407097447165 , Y grad GP:  tensor([ 1.6135, -1.9672, -0.0142,  2.5205,  0.2379, -0.9795],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.4223, -0.7130, -0.0094,  3.2601,  0.0164, -0.4133])\n",
            "\n",
            " Trial: 1, Iteration: 48, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/botorch/fit.py:171: RuntimeWarning: All attempts to fit the model have failed. For more information, try enabling botorch.settings.debug mode.\n",
            "  warn(str(err), RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best value:  -3.190577241261887 , X:  tensor([[0.4233, 0.9962, 0.2256, 0.0909, 0.3446, 0.0000]], dtype=torch.float64) AF:  tensor(0.7044, dtype=torch.float64) , Y:  -0.2689172797326602 , Y grad GP:  tensor([ 0.4684,  0.2570, -0.0935, -2.3774,  0.0747, -0.3659],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.1737,  0.5051, -0.0228, -2.5752,  0.0173, -0.3276])\n",
            "\n",
            " Trial: 1, Iteration: 49, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.2828, 0.6729, 0.1815, 0.9710, 0.0597, 0.0000]], dtype=torch.float64) AF:  tensor(0.7675, dtype=torch.float64) , Y:  -0.3464371283310722 , Y grad GP:  tensor([-1.7695, -2.1096, -0.1899,  2.4381, -0.0421, -1.1219],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-1.4333, -1.1620, -0.0244,  2.7495, -0.0044, -0.3703])\n",
            "\n",
            " Trial: 1, Iteration: 50, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[1.0000, 0.2070, 0.5833, 0.0000, 1.0000, 0.4890]], dtype=torch.float64) AF:  tensor(0.7025, dtype=torch.float64) , Y:  -0.0005093301259864818 , Y grad GP:  tensor([ 1.0013,  0.2584, -0.1646, -1.0759,  0.1003, -0.1746],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 8.1513e-03,  7.2325e-05,  3.5180e-04, -2.9137e-04,  1.4392e-03,\n",
            "        -9.9380e-04])\n",
            "\n",
            " Trial: 1, Iteration: 51, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.6175, 0.7680, 0.7986, 0.8842, 0.7557, 0.2538]], dtype=torch.float64) AF:  tensor(0.7249, dtype=torch.float64) , Y:  -0.25547287596700036 , Y grad GP:  tensor([ 2.8831, -0.6560, -0.0104,  2.2635,  0.2782,  2.9362],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.8476e+00, -4.6645e-01,  9.7647e-04,  1.5834e+00,  3.4218e-02,\n",
            "         1.5367e+00])\n",
            "\n",
            " Trial: 1, Iteration: 52, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.8735, 0.3004, 0.0000, 0.0766, 0.5741, 0.7534]], dtype=torch.float64) AF:  tensor(0.7025, dtype=torch.float64) , Y:  -0.11480352810448298 , Y grad GP:  tensor([ 1.8068,  0.2378,  0.0324, -1.5903,  0.0167, -0.0294],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.4401,  0.1247, -0.1377, -0.4857,  1.0509,  0.1623])\n",
            "\n",
            " Trial: 1, Iteration: 53, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.2585, 0.4002, 0.0000, 0.3895, 1.0000, 0.0000]], dtype=torch.float64) AF:  tensor(0.7184, dtype=torch.float64) , Y:  -0.21384382255602122 , Y grad GP:  tensor([-2.7905, -1.8269, -0.0200, -2.3032,  0.1920, -0.7583],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-1.0607, -1.6503, -0.0212, -0.7889,  0.0385, -0.2291])\n",
            "\n",
            " Trial: 1, Iteration: 54, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.7419, 1.0000, 0.5679, 0.3277, 0.9059, 0.0000]], dtype=torch.float64) AF:  tensor(0.7036, dtype=torch.float64) , Y:  -0.2067937275095047 , Y grad GP:  tensor([ 3.7589,  1.1279,  0.0065, -1.8790,  0.2118, -0.5068],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 2.3723,  0.3879, -0.0063, -1.0183,  0.0331, -0.2215])\n",
            "\n",
            " Trial: 1, Iteration: 55, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.6379, 0.6356, 0.7493, 0.2796, 0.5475, 0.0000]], dtype=torch.float64) AF:  tensor(0.6959, dtype=torch.float64) , Y:  -0.3211156890706949 , Y grad GP:  tensor([ 3.2766, -1.7562, -0.0168, -2.2062, -0.1771, -0.5922],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 2.5113, -1.2153,  0.0108, -1.8478,  0.0801, -0.4117])\n",
            "\n",
            " Trial: 1, Iteration: 56, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.8626, 0.0646, 0.6101, 0.1737, 0.8571, 0.5944]], dtype=torch.float64) AF:  tensor(0.6661, dtype=torch.float64) , Y:  -0.00793227327100236 , Y grad GP:  tensor([ 1.6221,  0.1711, -0.1403, -1.1490,  0.0922, -0.3498],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0728, -0.0058,  0.0094, -0.0042,  0.0736, -0.0057])\n",
            "\n",
            " Trial: 1, Iteration: 57, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.5403, 0.9749, 0.2010, 0.3584, 0.8995, 0.4280]], dtype=torch.float64) AF:  tensor(0.6488, dtype=torch.float64) , Y:  -0.1520764752494545 , Y grad GP:  tensor([ 2.8574,  1.3843, -0.0273, -2.3608, -0.0446,  2.8107],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.7051,  0.2307, -0.0302, -0.6435,  0.0300,  1.6345])\n",
            "\n",
            " Trial: 1, Iteration: 58, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.7521, 0.8538, 0.2023, 1.0000, 0.7729, 0.9006]], dtype=torch.float64) AF:  tensor(0.6145, dtype=torch.float64) , Y:  -3.7525545882421315e-05 , Y grad GP:  tensor([-0.1271,  1.0960, -0.2092,  0.2258,  0.1120, -0.7118],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0002,  0.0002, -0.0002,  0.0004,  0.0004,  0.0002])\n",
            "\n",
            " Trial: 1, Iteration: 59, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.0000, 0.0000, 0.6430, 0.7688, 0.0390, 0.4946]], dtype=torch.float64) AF:  tensor(0.6006, dtype=torch.float64) , Y:  -0.0814797985296159 , Y grad GP:  tensor([-0.2359, -0.2152, -0.1527,  0.6770, -0.3465, -0.5210],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.1465, -0.1064,  0.1143,  0.6244, -0.5212, -0.2223])\n",
            "\n",
            " Trial: 1, Iteration: 60, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.0\n",
            "Best value:  -3.190577241261887 , X:  tensor([[0.6212, 0.3809, 0.5543, 0.5575, 0.7014, 0.0000]], dtype=torch.float64) AF:  tensor(0.6467, dtype=torch.float64) , Y:  -0.18359276726469625 , Y grad GP:  tensor([ 3.2972e+00, -2.0863e+00, -2.6473e-03,  1.4607e-01, -7.0440e-02,\n",
            "        -4.0311e-01], dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.3474, -1.4450, -0.0049, -0.0463,  0.0399, -0.2235])\n",
            "\n",
            " Trial: 1, Iteration: 11, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.0038, 0.9694, 0.9955, 0.3410, 0.8793, 0.2700]], dtype=torch.float64) AF:  tensor(1.3604, dtype=torch.float64) , Y:  -0.0520458392206917 , Y grad GP:  tensor([-0.3225, -1.1388,  0.0457,  1.3807,  0.0383,  2.6813],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.6930,  0.0775,  0.0223, -0.2320,  0.0104,  0.3195])\n",
            "\n",
            " Trial: 1, Iteration: 12, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.2022, 0.6345, 0.8988, 0.6599, 0.1268, 0.5230]], dtype=torch.float64) AF:  tensor(0.7857, dtype=torch.float64) , Y:  -0.16555501594307462 , Y grad GP:  tensor([-4.1891, -0.0191, -0.5866,  1.5000,  0.4187, -1.6452],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.2413,  0.3418,  0.3222,  0.8115, -0.5912, -0.1451])\n",
            "\n",
            " Trial: 1, Iteration: 13, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/botorch/optim/optimize.py:369: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
            "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
            "Trying again with a new set of initial conditions.\n",
            "  warnings.warn(first_warn_msg, RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best value:  -1.16420343697261 , X:  tensor([[1.0000, 0.1923, 0.2742, 0.0892, 0.3038, 0.3604]], dtype=torch.float64) AF:  tensor(0.6376, dtype=torch.float64) , Y:  -0.1629250565662835 , Y grad GP:  tensor([ 1.5606, -0.0351, -0.1340, -2.1077,  0.3191, -0.4637],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.7488,  0.0538, -0.0438, -0.6481, -0.0051, -0.7937])\n",
            "\n",
            " Trial: 1, Iteration: 14, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.3532, 0.5504, 0.2643, 0.7529, 0.2259, 0.1425]], dtype=torch.float64) AF:  tensor(1.2462, dtype=torch.float64) , Y:  -0.7931831635672804 , Y grad GP:  tensor([ 0.4040,  0.5369, -0.0521,  1.2142,  0.1570, -0.9255],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-1.3310, -4.0536, -0.0674,  2.9409, -0.0350,  2.0898])\n",
            "\n",
            " Trial: 1, Iteration: 15, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.0012, 0.9322, 0.7606, 0.1269, 0.4881, 0.1402]], dtype=torch.float64) AF:  tensor(1.2594, dtype=torch.float64) , Y:  -0.04463198814501998 , Y grad GP:  tensor([-0.0687, -0.1766,  0.0173, -0.8153,  0.1931,  0.1096],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.3557,  0.1284,  0.0936, -0.2276,  0.0541, -0.1060])\n",
            "\n",
            " Trial: 1, Iteration: 16, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.9915, 0.0582, 0.0548, 0.6357, 0.8436, 0.1133]], dtype=torch.float64) AF:  tensor(1.2760, dtype=torch.float64) , Y:  -0.00011762159661765187 , Y grad GP:  tensor([-0.3077, -0.8130, -0.1371,  0.2871,  0.2947, -0.6043],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.0421e-03, -4.8119e-04, -9.4229e-05,  6.3045e-04,  1.5647e-03,\n",
            "        -6.8338e-04])\n",
            "\n",
            " Trial: 1, Iteration: 17, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.2245, 0.3210, 0.5615, 0.5959, 0.7704, 0.1369]], dtype=torch.float64) AF:  tensor(1.2220, dtype=torch.float64) , Y:  -0.17512849147429385 , Y grad GP:  tensor([-2.1416, -2.0291,  0.0507,  1.2204,  0.2174,  1.0250],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.6531, -1.0483,  0.0059,  0.2749,  0.0476, -0.0500])\n",
            "\n",
            " Trial: 1, Iteration: 18, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -1.16420343697261 , X:  tensor([[1.0000, 0.8858, 0.6334, 0.8062, 0.3505, 0.1494]], dtype=torch.float64) AF:  tensor(1.1836, dtype=torch.float64) , Y:  -0.004293922192896068 , Y grad GP:  tensor([-0.3611, -0.2059, -0.0356,  1.0684, -0.0779,  2.5021],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([0.0791, 0.0029, 0.0004, 0.0229, 0.0010, 0.0074])\n",
            "\n",
            " Trial: 1, Iteration: 19, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.2345, 0.8848, 0.1026, 0.9018, 0.1685, 0.1626]], dtype=torch.float64) AF:  tensor(1.0430, dtype=torch.float64) , Y:  -0.5234991848771888 , Y grad GP:  tensor([-0.9918, -0.2030, -0.1191,  1.9129,  0.0764,  2.3713],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.0204e+00,  2.1846e-02, -4.1657e-02,  3.4330e+00,  1.9902e-03,\n",
            "         1.8124e+00])\n",
            "\n",
            " Trial: 1, Iteration: 20, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -1.7687779092311684 , X:  tensor([[0.4834, 0.6707, 0.6276, 0.5169, 0.1920, 0.1294]], dtype=torch.float64) AF:  tensor(0.8697, dtype=torch.float64) , Y:  -1.7687779092311684 , Y grad GP:  tensor([ 0.0419, -1.5916,  0.0380, -1.6943,  0.0319,  1.9292],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 4.6969, -5.6851,  0.0066, -1.7766, -0.1353,  4.0235])\n",
            "\n",
            " Trial: 1, Iteration: 21, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -1.7687779092311684 , X:  tensor([[0.6926, 0.8323, 0.0184, 0.5513, 1.0000, 0.1170]], dtype=torch.float64) AF:  tensor(1.3259, dtype=torch.float64) , Y:  -0.622257416984368 , Y grad GP:  tensor([-0.2463, -1.0506,  0.0196, -1.0470, -0.0317,  2.4661],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 6.0895, -0.5027, -0.0533, -0.2861,  0.1109,  1.3736])\n",
            "\n",
            " Trial: 1, Iteration: 22, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/botorch/optim/optimize.py:369: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
            "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
            "Trying again with a new set of initial conditions.\n",
            "  warnings.warn(first_warn_msg, RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best value:  -1.7687779092311684 , X:  tensor([[0.4435, 0.7510, 0.8044, 0.4867, 1.0000, 0.2380]], dtype=torch.float64) AF:  tensor(1.2875, dtype=torch.float64) , Y:  -1.3346000729116847 , Y grad GP:  tensor([ 0.2397, -2.0827,  0.0618, -1.4069, -0.0856,  2.0446],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.7968, -2.7682,  0.0566, -2.2964,  0.2415,  7.3761])\n",
            "\n",
            " Trial: 1, Iteration: 23, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.6728381852574383 , X:  tensor([[0.4079, 0.7732, 0.7539, 0.5538, 1.0000, 0.0435]], dtype=torch.float64) AF:  tensor(1.6616, dtype=torch.float64) , Y:  -2.6728381852574383 , Y grad GP:  tensor([ 0.4094, -1.4655, -0.1437, -0.9471,  0.2105,  2.2464],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.3061, -4.6695, -0.0148, -1.0860,  0.4774,  0.3800])\n",
            "\n",
            " Trial: 1, Iteration: 24, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.6728381852574383 , X:  tensor([[0.3034, 0.7809, 0.4011, 0.5572, 0.0010, 0.0000]], dtype=torch.float64) AF:  tensor(2.4661, dtype=torch.float64) , Y:  -2.389845710963596 , Y grad GP:  tensor([-1.1961, -2.2738,  0.0103, -0.9695,  0.4837, -0.3571],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-8.2060, -3.8760, -0.1182, -0.8018, -0.0765, -2.5754])\n",
            "\n",
            " Trial: 1, Iteration: 25, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.6728381852574383 , X:  tensor([[0.6078, 0.7400, 0.7338, 0.6106, 0.9704, 0.0000]], dtype=torch.float64) AF:  tensor(1.6689, dtype=torch.float64) , Y:  -1.210118236714369 , Y grad GP:  tensor([ 3.6051, -2.3014, -0.0843,  0.2647,  0.2293, -1.8082],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 8.3487, -2.7597, -0.0145,  0.8800,  0.2086, -1.2925])\n",
            "\n",
            " Trial: 1, Iteration: 26, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.6728381852574383 , X:  tensor([[0.6412, 0.9762, 0.5845, 0.4241, 1.0000, 0.0000]], dtype=torch.float64) AF:  tensor(1.1653, dtype=torch.float64) , Y:  -0.8298060698720763 , Y grad GP:  tensor([ 5.1788, -1.5881, -0.0618, -1.7610,  0.1810, -3.1858],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 6.6696,  1.2401, -0.0236, -2.4880,  0.1480, -0.8869])\n",
            "\n",
            " Trial: 1, Iteration: 27, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.3935, 0.8722, 0.1730, 0.5792, 0.6920, 0.0022]], dtype=torch.float64) AF:  tensor(2.6546, dtype=torch.float64) , Y:  -2.9551022007874628 , Y grad GP:  tensor([-1.0841, -2.0270, -0.0946, -0.3942,  0.3174, -2.0078],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-1.1259, -0.4969, -0.2096,  0.2942,  0.3498, -2.9720])\n",
            "\n",
            " Trial: 1, Iteration: 28, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.9488, 0.0000, 0.1086, 0.0000, 0.1823, 0.9303]], dtype=torch.float64) AF:  tensor(0.9175, dtype=torch.float64) , Y:  -0.10499899732113198 , Y grad GP:  tensor([ 1.2855, -0.1561, -0.0172, -0.4798, -0.1993, -0.4660],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.4498, -0.1068, -0.0877, -0.6050, -0.4363,  0.4453])\n",
            "\n",
            " Trial: 1, Iteration: 29, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.4083, 0.6041, 0.7321, 0.5761, 0.4859, 0.0000]], dtype=torch.float64) AF:  tensor(2.3169, dtype=torch.float64) , Y:  -1.6686596770664104 , Y grad GP:  tensor([ 0.6992, -2.1855, -0.0107, -0.3491,  0.0600, -1.0197],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 2.2750e-01, -7.3618e+00,  1.9009e-03,  1.1261e-01,  1.6780e-01,\n",
            "        -1.8712e+00])\n",
            "\n",
            " Trial: 1, Iteration: 30, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.5238, 0.9282, 1.0000, 0.8055, 0.7209, 0.0000]], dtype=torch.float64) AF:  tensor(1.6988, dtype=torch.float64) , Y:  -1.3662766243762479 , Y grad GP:  tensor([ 5.0951e+00,  5.1129e-01, -1.9841e-03,  2.3228e+00,  2.3098e-01,\n",
            "        -7.7080e-01], dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 5.5260,  0.9925,  0.0175,  6.3150,  0.1674, -1.4557])\n",
            "\n",
            " Trial: 1, Iteration: 31, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.3906, 1.0000, 0.0000, 0.6436, 0.9973, 0.2859]], dtype=torch.float64) AF:  tensor(1.5960, dtype=torch.float64) , Y:  -1.0252892551950266 , Y grad GP:  tensor([-0.8315,  0.8065,  0.0071,  0.3544,  0.1593,  3.6475],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.4890,  1.9213, -0.0902,  1.4208,  0.1823,  7.1099])\n",
            "\n",
            " Trial: 1, Iteration: 32, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.3093, 0.9363, 0.5109, 0.2700, 0.0093, 0.0000]], dtype=torch.float64) AF:  tensor(1.5195, dtype=torch.float64) , Y:  -1.0363336945231132 , Y grad GP:  tensor([-4.5848,  0.2562, -0.0064, -2.6597,  0.0273, -1.3930],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.3349,  0.9029, -0.0393, -6.2775, -0.0468, -1.1399])\n",
            "\n",
            " Trial: 1, Iteration: 33, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.1013, 1.0000, 0.0000, 0.5565, 0.2471, 0.0000]], dtype=torch.float64) AF:  tensor(1.3423, dtype=torch.float64) , Y:  -0.5649668649725649 , Y grad GP:  tensor([-4.8776,  0.7497, -0.2119, -0.8779,  0.1031, -2.6526],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-5.8058,  1.0685, -0.0521, -0.1869,  0.0108, -0.6248])\n",
            "\n",
            " Trial: 1, Iteration: 34, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.5098, 0.8212, 0.0000, 0.9194, 0.2560, 0.1816]], dtype=torch.float64) AF:  tensor(1.0948, dtype=torch.float64) , Y:  -0.5640245027464718 , Y grad GP:  tensor([ 3.8223, -0.3666, -0.0193,  3.3736, -0.0839,  3.0138],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 2.0100, -0.5497, -0.0505,  3.8984,  0.0148,  2.2512])\n",
            "\n",
            " Trial: 1, Iteration: 35, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.2478, 1.0000, 0.0076, 0.9995, 0.6499, 0.0000]], dtype=torch.float64) AF:  tensor(0.8773, dtype=torch.float64) , Y:  -0.28369715604019036 , Y grad GP:  tensor([-1.9794,  0.6009, -0.0659,  3.8315,  0.1509, -2.0505],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-1.5115,  0.5316, -0.0246,  2.4129,  0.0307, -0.3023])\n",
            "\n",
            " Trial: 1, Iteration: 36, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.5342, 0.6572, 0.2010, 0.6461, 0.8288, 0.3885]], dtype=torch.float64) AF:  tensor(0.9352, dtype=torch.float64) , Y:  -0.25632243837691715 , Y grad GP:  tensor([ 3.7873, -1.4649, -0.1323,  1.0580, -0.0091,  3.6871],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.1312, -0.9025, -0.0418,  0.3809,  0.0587,  2.4718])\n",
            "\n",
            " Trial: 1, Iteration: 37, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.1025, 0.6721, 0.0225, 0.6852, 0.6332, 0.0000]], dtype=torch.float64) AF:  tensor(1.0156, dtype=torch.float64) , Y:  -0.387126129177424 , Y grad GP:  tensor([-4.5087, -2.9341, -0.0474,  2.5881,  0.0528, -1.4717],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.9688, -1.2982, -0.0346,  0.8633,  0.0501, -0.4210])\n",
            "\n",
            " Trial: 1, Iteration: 38, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.5568, 0.9484, 0.0000, 0.3040, 0.1891, 0.1634]], dtype=torch.float64) AF:  tensor(1.0828, dtype=torch.float64) , Y:  -0.7954065223290958 , Y grad GP:  tensor([ 4.1184,  0.9373, -0.0732, -2.0902, -0.0433,  3.0432],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 4.0444,  0.9245, -0.0916, -4.1852, -0.0652,  2.5603])\n",
            "\n",
            " Trial: 1, Iteration: 39, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.2917, 0.9619, 1.0000, 0.4600, 0.8654, 0.3690]], dtype=torch.float64) AF:  tensor(0.9218, dtype=torch.float64) , Y:  -0.439540826870476 , Y grad GP:  tensor([-3.4006,  1.0939,  0.0819, -0.4511,  0.1146,  3.3321],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-1.6750,  0.5621,  0.0273, -0.9948,  0.0712,  4.0515])\n",
            "\n",
            " Trial: 1, Iteration: 40, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.4717, 0.9932, 1.0000, 0.1807, 1.0000, 0.0000]], dtype=torch.float64) AF:  tensor(0.9904, dtype=torch.float64) , Y:  -0.5168241769463369 , Y grad GP:  tensor([ 1.5807,  1.0940,  0.0422, -3.0113,  0.1851, -0.3334],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.1755,  0.9126,  0.0077, -4.0677,  0.0921, -0.5512])\n",
            "\n",
            " Trial: 1, Iteration: 41, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.4647, 0.4222, 0.5490, 0.5562, 0.0851, 0.1031]], dtype=torch.float64) AF:  tensor(0.9959, dtype=torch.float64) , Y:  -0.5523861563218628 , Y grad GP:  tensor([ 2.7950, -2.7446, -0.0297, -0.8857,  0.0251,  1.5779],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.1310e+00, -3.7274e+00,  2.7979e-03,  3.6419e-03, -2.5198e-01,\n",
            "         6.0858e-01])\n",
            "\n",
            " Trial: 1, Iteration: 42, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.6517, 1.0000, 0.8067, 1.0000, 0.7798, 0.0000]], dtype=torch.float64) AF:  tensor(0.7743, dtype=torch.float64) , Y:  -0.1554238967140227 , Y grad GP:  tensor([ 3.0889,  0.6582, -0.1555,  3.0924,  0.0701, -1.2608],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.3046e+00,  2.9126e-01, -9.8276e-04,  1.3235e+00,  2.0852e-02,\n",
            "        -1.6563e-01])\n",
            "\n",
            " Trial: 1, Iteration: 43, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.1599, 0.5763, 0.5861, 0.4214, 0.4415, 0.0000]], dtype=torch.float64) AF:  tensor(0.9286, dtype=torch.float64) , Y:  -0.4572865525957367 , Y grad GP:  tensor([-4.2767, -2.6109,  0.0121, -2.6050,  0.0771, -1.2863],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.4651, -1.9266,  0.0237, -1.1605,  0.1220, -0.8597])\n",
            "\n",
            " Trial: 1, Iteration: 44, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.7576, 0.3136, 0.3333, 0.0000, 0.6280, 0.6279]], dtype=torch.float64) AF:  tensor(0.7231, dtype=torch.float64) , Y:  -0.09469732721724854 , Y grad GP:  tensor([ 1.1011,  0.2110, -0.1376, -1.2635, -0.3745, -0.3809],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.3652,  0.1085, -0.0654, -0.5028,  0.9551, -0.0495])\n",
            "\n",
            " Trial: 1, Iteration: 45, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[1.0000, 0.2719, 0.3899, 0.2879, 0.7942, 0.6910]], dtype=torch.float64) AF:  tensor(0.7479, dtype=torch.float64) , Y:  -0.008693429333666064 , Y grad GP:  tensor([ 1.1970,  0.2026, -0.1126, -0.9685,  0.4587, -0.4316],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0419,  0.0069, -0.0032,  0.0004,  0.1402,  0.0021])\n",
            "\n",
            " Trial: 1, Iteration: 46, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.9366, 0.0058, 0.0449, 0.0000, 0.8725, 0.5834]], dtype=torch.float64) AF:  tensor(0.7071, dtype=torch.float64) , Y:  -0.0009545362977033829 , Y grad GP:  tensor([ 1.4216,  0.0543, -0.2709, -0.8199,  0.1102, -0.5418],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0042, -0.0009, -0.0013, -0.0054,  0.0182, -0.0012])\n",
            "\n",
            " Trial: 1, Iteration: 47, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.6237, 0.5743, 0.0397, 0.3813, 0.2282, 0.1828]], dtype=torch.float64) AF:  tensor(0.7965, dtype=torch.float64) , Y:  -0.43748576020682217 , Y grad GP:  tensor([ 4.0517, -2.2027, -0.0620, -1.9619, -0.0369,  2.4846],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 2.6953, -1.2890, -0.1446, -1.0611, -0.2766,  0.4819])\n",
            "\n",
            " Trial: 1, Iteration: 48, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[9.9491e-01, 4.0836e-01, 6.4096e-01, 0.0000e+00, 2.2503e-04, 6.0169e-01]],\n",
            "       dtype=torch.float64) AF:  tensor(0.7167, dtype=torch.float64) , Y:  -0.09463921587717701 , Y grad GP:  tensor([ 1.3279,  0.1485,  0.1905, -0.5973, -0.2215, -0.4628],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.1507,  0.0517, -0.3748, -0.1862, -0.4273, -0.7335])\n",
            "\n",
            " Trial: 1, Iteration: 49, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.6779, 0.6864, 0.8279, 0.3029, 0.7949, 0.0000]], dtype=torch.float64) AF:  tensor(0.6862, dtype=torch.float64) , Y:  -0.29630283319161244 , Y grad GP:  tensor([ 3.7361, -1.0468,  0.0216, -2.1791,  0.1617, -0.7851],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 2.7504e+00, -9.2718e-01,  1.7575e-03, -1.6043e+00,  4.3854e-02,\n",
            "        -3.2008e-01])\n",
            "\n",
            " Trial: 1, Iteration: 50, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.7474, 0.7738, 0.9951, 1.0000, 0.3601, 1.0000]], dtype=torch.float64) AF:  tensor(0.6515, dtype=torch.float64) , Y:  -0.11488109233168119 , Y grad GP:  tensor([ 0.1224,  0.8408, -0.1391, -0.1429,  0.5011, -0.5159],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([0.0072, 0.8266, 0.6402, 0.0203, 0.4761, 0.0051])\n",
            "\n",
            " Trial: 1, Iteration: 51, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/botorch/optim/optimize.py:369: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
            "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
            "Trying again with a new set of initial conditions.\n",
            "  warnings.warn(first_warn_msg, RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best value:  -2.9551022007874628 , X:  tensor([[0.5943, 1.0000, 1.0000, 0.4509, 0.4057, 0.3759]], dtype=torch.float64) AF:  tensor(0.7235, dtype=torch.float64) , Y:  -0.2936526632209691 , Y grad GP:  tensor([ 3.1037,  1.1085,  0.0327, -1.6767,  0.1564,  3.3252],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.7813,  0.6562,  0.0620, -0.5769,  0.1036,  2.4149])\n",
            "\n",
            " Trial: 1, Iteration: 52, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.0000, 0.0000, 0.8456, 0.7796, 0.3295, 0.5607]], dtype=torch.float64) AF:  tensor(0.6349, dtype=torch.float64) , Y:  -0.15176389736109858 , Y grad GP:  tensor([-0.2707, -0.1583,  0.1846,  0.8337,  0.3446, -0.7925],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.2196, -0.2228,  0.3699,  1.3306,  0.1149, -0.3345])\n",
            "\n",
            " Trial: 1, Iteration: 53, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.0793, 0.8043, 0.5402, 0.3702, 0.5910, 0.0000]], dtype=torch.float64) AF:  tensor(0.6261, dtype=torch.float64) , Y:  -0.3304133318988359 , Y grad GP:  tensor([-3.1667, -0.4150, -0.0183, -1.6948,  0.1393, -0.3792],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.5120, -0.3389, -0.0140, -1.2567,  0.0597, -0.4770])\n",
            "\n",
            " Trial: 1, Iteration: 54, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.7454, 1.0000, 0.0000, 0.7038, 0.8570, 0.0000]], dtype=torch.float64) AF:  tensor(0.6745, dtype=torch.float64) , Y:  -0.3004935853709382 , Y grad GP:  tensor([ 3.8700,  0.6764, -0.0329,  2.4200, -0.0357, -0.8700],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 3.4828,  0.5631, -0.0262,  0.7777,  0.0450, -0.3201])\n",
            "\n",
            " Trial: 1, Iteration: 55, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/botorch/optim/optimize.py:369: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
            "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
            "Trying again with a new set of initial conditions.\n",
            "  warnings.warn(first_warn_msg, RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best value:  -2.9551022007874628 , X:  tensor([[0.4200, 0.6886, 0.7727, 1.0000, 0.3830, 0.0000]], dtype=torch.float64) AF:  tensor(0.8050, dtype=torch.float64) , Y:  -0.3744136636759145 , Y grad GP:  tensor([ 8.2475e-01, -2.1078e+00, -2.4154e-03,  2.4295e+00,  9.0703e-02,\n",
            "        -1.0486e+00], dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.9529e-01, -1.1610e+00, -2.6482e-03,  3.1889e+00,  2.0617e-02,\n",
            "        -4.0109e-01])\n",
            "\n",
            " Trial: 1, Iteration: 56, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.6293, 0.5457, 0.2220, 0.7420, 0.1991, 0.1695]], dtype=torch.float64) AF:  tensor(0.6830, dtype=torch.float64) , Y:  -0.33272887623085795 , Y grad GP:  tensor([ 3.6104, -2.3101, -0.0177,  2.2644, -0.1478,  1.6080],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 2.4581, -1.6663, -0.0293,  1.2037, -0.0500,  1.0417])\n",
            "\n",
            " Trial: 1, Iteration: 57, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[4.2405e-01, 6.7015e-01, 3.1902e-04, 1.0000e+00, 4.0973e-01, 8.8735e-01]],\n",
            "       dtype=torch.float64) AF:  tensor(0.6011, dtype=torch.float64) , Y:  -0.002959427889308672 , Y grad GP:  tensor([ 0.0567,  0.9629,  0.0462,  0.4768,  0.4442, -0.7256],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0034,  0.0108, -0.0038,  0.0420,  0.0104,  0.0108])\n",
            "\n",
            " Trial: 1, Iteration: 58, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.6826, 1.0000, 1.0000, 0.7549, 0.9454, 0.2034]], dtype=torch.float64) AF:  tensor(0.6445, dtype=torch.float64) , Y:  -0.3535463184354377 , Y grad GP:  tensor([3.2982, 0.6758, 0.0273, 1.9193, 0.0301, 2.9002], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>) , Y grad query:  tensor([3.3404, 0.6625, 0.0046, 1.2763, 0.0592, 1.6348])\n",
            "\n",
            " Trial: 1, Iteration: 59, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.8555, 0.2289, 0.1663, 0.1850, 0.8073, 0.5269]], dtype=torch.float64) AF:  tensor(0.6192, dtype=torch.float64) , Y:  -0.00950851948394348 , Y grad GP:  tensor([ 1.7537,  0.2073, -0.1241, -1.4721,  0.1843, -0.5637],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0394,  0.0052, -0.0103, -0.0186,  0.1567, -0.0202])\n",
            "\n",
            " Trial: 1, Iteration: 60, Penalty: 10, Beta mean: 1.0, Beta constraint: 2.5\n",
            "Best value:  -2.9551022007874628 , X:  tensor([[0.2909, 0.7376, 0.5511, 0.1216, 0.9696, 0.0000]], dtype=torch.float64) AF:  tensor(0.6307, dtype=torch.float64) , Y:  -0.2701338229659405 , Y grad GP:  tensor([-1.9237, -0.7609, -0.0091, -2.6339,  0.1627, -0.7328],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.9232, -0.5293, -0.0115, -2.2788,  0.0520, -0.4305])\n",
            "\n",
            " Trial: 1, Iteration: 11, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -1.16420343697261 , X:  tensor([[0.0406, 0.9685, 0.9961, 0.0145, 0.8799, 0.4451]], dtype=torch.float64) AF:  tensor(1.3604, dtype=torch.float64) , Y:  -0.005744378647956402 , Y grad GP:  tensor([-0.7367, -0.1688,  0.0199,  1.3001,  0.0380,  2.7134],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.0238,  0.0233,  0.0650, -0.0150,  0.0038,  0.0041])\n",
            "\n",
            " Trial: 1, Iteration: 12, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -1.54198980035854 , X:  tensor([[0.5534, 0.8857, 0.6677, 0.7540, 0.3532, 0.0801]], dtype=torch.float64) AF:  tensor(1.2037, dtype=torch.float64) , Y:  -1.54198980035854 , Y grad GP:  tensor([-4.1123, -0.1868, -0.0612, -2.1831,  0.0113,  0.6470],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 7.7792,  0.0824, -0.0282,  5.5499,  0.0778,  1.7889])\n",
            "\n",
            " Trial: 1, Iteration: 13, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -1.54198980035854 , X:  tensor([[0.4897, 0.3942, 0.7623, 1.0000, 0.2936, 0.0000]], dtype=torch.float64) AF:  tensor(1.9001, dtype=torch.float64) , Y:  -0.06724505064303718 , Y grad GP:  tensor([ 2.8383, -1.6384,  0.0501,  1.9985, -0.1189, -0.8807],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.1942, -0.5218,  0.0007,  0.5740,  0.0021, -0.0755])\n",
            "\n",
            " Trial: 1, Iteration: 14, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -1.54198980035854 , X:  tensor([[0.8096, 0.9235, 0.6668, 0.7986, 0.6537, 0.9490]], dtype=torch.float64) AF:  tensor(1.6777, dtype=torch.float64) , Y:  -0.005153601450251378 , Y grad GP:  tensor([1.8454e-01, 1.5506e-01, 1.6665e-05, 8.9159e-02, 4.1526e-03, 2.2888e+00],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0030,  0.0496, -0.0245,  0.0063,  0.0468, -0.0035])\n",
            "\n",
            " Trial: 1, Iteration: 15, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -1.54198980035854 , X:  tensor([[0.0000, 0.8836, 0.8682, 0.8332, 0.1964, 0.0172]], dtype=torch.float64) AF:  tensor(1.6191, dtype=torch.float64) , Y:  -0.10089715079449615 , Y grad GP:  tensor([0.0137, 0.3220, 0.0218, 4.2011, 0.1224, 0.7258], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>) , Y grad query:  tensor([-1.3846e+00,  3.5944e-03,  1.8754e-03,  5.2426e-01,  1.9669e-04,\n",
            "        -6.3508e-02])\n",
            "\n",
            " Trial: 1, Iteration: 16, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -2.6091067081025323 , X:  tensor([[0.4931, 0.8921, 0.4785, 0.6326, 0.2981, 0.0831]], dtype=torch.float64) AF:  tensor(1.4744, dtype=torch.float64) , Y:  -2.6091067081025323 , Y grad GP:  tensor([ 5.1856,  0.1341, -0.0452,  3.2754,  0.0556,  1.4769],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 7.8203,  0.4290, -0.1025,  3.0846,  0.0949,  3.2017])\n",
            "\n",
            " Trial: 1, Iteration: 17, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -2.6091067081025323 , X:  tensor([[0.5350, 0.4064, 0.1295, 0.5839, 0.5591, 0.0072]], dtype=torch.float64) AF:  tensor(2.7265, dtype=torch.float64) , Y:  -0.3741384701840237 , Y grad GP:  tensor([ 0.5510, -0.7737,  0.0505,  1.9058, -0.0294,  0.2467],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.6365, -2.7826, -0.0348,  0.1136,  0.0953, -0.3946])\n",
            "\n",
            " Trial: 1, Iteration: 18, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -2.6091067081025323 , X:  tensor([[0.6306, 0.9150, 0.9404, 0.5903, 0.3915, 0.0776]], dtype=torch.float64) AF:  tensor(2.4857, dtype=torch.float64) , Y:  -1.2933686272206137 , Y grad GP:  tensor([ 5.3622, -0.0089, -0.0987,  1.9065, -0.0403,  1.6421],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([9.9103, 0.6800, 0.0150, 0.4301, 0.0815, 1.3958])\n",
            "\n",
            " Trial: 1, Iteration: 19, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.102865209274462 , X:  tensor([[0.3928, 0.8826, 0.5231, 0.5717, 0.5961, 0.0381]], dtype=torch.float64) AF:  tensor(2.6886, dtype=torch.float64) , Y:  -3.102865209274462 , Y grad GP:  tensor([ 2.2193,  0.5705, -0.0255,  1.9088,  0.0985,  0.6656],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-1.2395,  0.0095, -0.1108, -0.1396,  0.3173, -0.0399])\n",
            "\n",
            " Trial: 1, Iteration: 20, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.102865209274462 , X:  tensor([[0.6914, 0.9547, 0.5797, 0.5566, 0.9054, 0.0000]], dtype=torch.float64) AF:  tensor(3.2900, dtype=torch.float64) , Y:  -0.6931013436762493 , Y grad GP:  tensor([ 1.1637,  0.4781, -0.0717, -1.2238,  0.3168,  0.5289],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 6.7559,  0.7969, -0.0202, -0.2449,  0.1105, -0.7397])\n",
            "\n",
            " Trial: 1, Iteration: 21, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.102865209274462 , X:  tensor([[0.4091, 0.9465, 0.7144, 0.5558, 0.2623, 0.6402]], dtype=torch.float64) AF:  tensor(3.2509, dtype=torch.float64) , Y:  -0.14589588461981 , Y grad GP:  tensor([ 0.8843,  0.3142,  0.0171,  0.8391,  0.0529, -0.2157],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.1729,  0.7582,  0.1585,  0.6155, -0.1568,  0.2155])\n",
            "\n",
            " Trial: 1, Iteration: 22, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.102865209274462 , X:  tensor([[0.4146, 0.9160, 0.0000, 0.5644, 0.9509, 0.0429]], dtype=torch.float64) AF:  tensor(3.2013, dtype=torch.float64) , Y:  -2.836035800178923 , Y grad GP:  tensor([-0.3256,  0.2295, -0.2191, -0.3580,  0.2192,  0.0878],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.9535,  1.5032, -0.2479, -0.5617,  0.4776,  0.3836])\n",
            "\n",
            " Trial: 1, Iteration: 23, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1378775826371252 , X:  tensor([[0.4173, 0.8492, 0.4544, 0.5745, 0.0606, 0.0425]], dtype=torch.float64) AF:  tensor(3.2188, dtype=torch.float64) , Y:  -3.1378775826371252 , Y grad GP:  tensor([ 0.8743, -0.4417, -0.1666, -0.1106,  0.0141,  1.1113],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.3503, -1.6626, -0.1336,  0.0345, -0.0612,  0.3445])\n",
            "\n",
            " Trial: 1, Iteration: 24, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1378775826371252 , X:  tensor([[4.0939e-01, 8.6090e-01, 1.0000e+00, 5.8496e-01, 1.6410e-01, 8.0128e-04]],\n",
            "       dtype=torch.float64) AF:  tensor(3.2285, dtype=torch.float64) , Y:  -3.120069375314588 , Y grad GP:  tensor([ 3.1983, -0.4554,  0.0117,  0.4446,  0.0449, -0.2114],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.4981, -1.0819,  0.0444,  0.6756,  0.0250, -3.2729])\n",
            "\n",
            " Trial: 1, Iteration: 25, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.4061, 0.8793, 1.0000, 0.5744, 0.0000, 0.0419]], dtype=torch.float64) AF:  tensor(3.1518, dtype=torch.float64) , Y:  -3.1934105118549 , Y grad GP:  tensor([ 0.1514, -0.3273,  0.0491,  0.0788, -0.0518, -0.6868],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.1534, -0.1763,  0.0428,  0.0138, -0.0784,  0.3326])\n",
            "\n",
            " Trial: 1, Iteration: 26, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/botorch/optim/optimize.py:369: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
            "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
            "Trying again with a new set of initial conditions.\n",
            "  warnings.warn(first_warn_msg, RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best value:  -3.1934105118549 , X:  tensor([[0.3838, 0.8753, 0.7582, 0.4797, 0.0945, 0.0328]], dtype=torch.float64) AF:  tensor(3.0742, dtype=torch.float64) , Y:  -2.9053211595136594 , Y grad GP:  tensor([-1.7122, -0.3765, -0.0177, -2.5562, -0.0171, -0.9760],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-2.0479, -0.3196, -0.0209, -5.4621, -0.0421, -0.4814])\n",
            "\n",
            " Trial: 1, Iteration: 27, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.4057, 0.8758, 0.6305, 0.5673, 0.1878, 0.0776]], dtype=torch.float64) AF:  tensor(3.1862, dtype=torch.float64) , Y:  -3.1275458287434663 , Y grad GP:  tensor([ 0.1202, -0.2190, -0.0465, -0.4102,  0.0153,  0.1795],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.1288, -0.2983, -0.0625, -0.3809,  0.0107,  3.3437])\n",
            "\n",
            " Trial: 1, Iteration: 28, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.4028, 0.8130, 1.0000, 0.5732, 0.0349, 0.0563]], dtype=torch.float64) AF:  tensor(2.9616, dtype=torch.float64) , Y:  -3.0609658342040436 , Y grad GP:  tensor([-0.1749, -1.8511, -0.0084, -0.0523, -0.1017, -0.3781],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.1954, -3.4063,  0.0438, -0.0572, -0.0628,  1.5337])\n",
            "\n",
            " Trial: 1, Iteration: 29, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.4054, 0.8616, 0.6814, 0.5714, 0.2775, 0.1643]], dtype=torch.float64) AF:  tensor(2.8978, dtype=torch.float64) , Y:  -2.5660031407179518 , Y grad GP:  tensor([ 0.0985, -0.3604, -0.0314,  0.0052,  0.0243,  3.2501],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.0225e-01, -7.2975e-01, -6.1703e-03, -4.8466e-03,  5.6990e-02,\n",
            "         8.7518e+00])\n",
            "\n",
            " Trial: 1, Iteration: 30, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[3.0721e-01, 9.9957e-01, 9.7195e-02, 3.4126e-01, 3.9294e-01, 7.5020e-04]],\n",
            "       dtype=torch.float64) AF:  tensor(2.0783, dtype=torch.float64) , Y:  -1.3439425183805997 , Y grad GP:  tensor([-4.8790,  0.3859, -0.0363, -3.8170,  0.1969, -2.3148],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-4.4283,  2.5304, -0.1096, -6.2299,  0.0912, -1.4534])\n",
            "\n",
            " Trial: 1, Iteration: 31, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.3601, 0.6636, 0.0888, 0.5898, 0.0000, 0.2118]], dtype=torch.float64) AF:  tensor(1.8458, dtype=torch.float64) , Y:  -1.350716868186493 , Y grad GP:  tensor([-2.8212, -3.0952, -0.3096,  0.8962,  0.0315,  4.8387],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-2.0058, -4.6184, -0.1224,  0.5100, -0.1950,  6.3656])\n",
            "\n",
            " Trial: 1, Iteration: 32, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.3401, 0.9895, 0.3352, 0.7936, 0.0000, 0.0210]], dtype=torch.float64) AF:  tensor(2.2421, dtype=torch.float64) , Y:  -1.6497110395371115 , Y grad GP:  tensor([-4.6572,  2.4427, -0.0531,  4.0028, -0.0310, -0.9986],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.6190,  2.8164, -0.0895,  7.2303, -0.0377, -0.7908])\n",
            "\n",
            " Trial: 1, Iteration: 33, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/botorch/optim/optimize.py:369: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
            "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
            "Trying again with a new set of initial conditions.\n",
            "  warnings.warn(first_warn_msg, RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best value:  -3.1934105118549 , X:  tensor([[0.4063, 0.8908, 0.3603, 0.5888, 0.1738, 0.2546]], dtype=torch.float64) AF:  tensor(1.9811, dtype=torch.float64) , Y:  -1.667849241200376 , Y grad GP:  tensor([ 0.1507,  0.8028, -0.0304,  0.7612, -0.0527,  3.3705],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.1385,  0.3844, -0.1041,  0.6713, -0.1231,  9.6753])\n",
            "\n",
            " Trial: 1, Iteration: 34, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.3025, 0.5587, 0.7966, 0.6045, 0.0000, 0.0000]], dtype=torch.float64) AF:  tensor(1.6713, dtype=torch.float64) , Y:  -1.1248173351707857 , Y grad GP:  tensor([-2.1689, -2.9262, -0.0313,  1.3714, -0.2107, -1.7816],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.8843e+00, -5.8026e+00,  3.5825e-03,  6.9638e-01, -5.3923e-02,\n",
            "        -1.2314e+00])\n",
            "\n",
            " Trial: 1, Iteration: 35, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.3987, 0.7688, 1.0000, 0.5742, 0.9631, 0.0320]], dtype=torch.float64) AF:  tensor(2.7390, dtype=torch.float64) , Y:  -2.676325938722977 , Y grad GP:  tensor([-0.4969, -2.7786,  0.0233,  0.0052,  0.4103, -0.5695],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.5474, -4.8753,  0.0363, -0.0069,  0.4572, -0.4598])\n",
            "\n",
            " Trial: 1, Iteration: 36, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.4021, 0.8219, 0.0214, 0.2534, 0.0085, 0.0000]], dtype=torch.float64) AF:  tensor(1.5505, dtype=torch.float64) , Y:  -1.0501496477658667 , Y grad GP:  tensor([ 0.0525, -1.9935, -0.2491, -3.4446, -0.0881, -1.8033],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.0891, -1.0058, -0.0929, -6.7202, -0.0511, -1.1475])\n",
            "\n",
            " Trial: 1, Iteration: 37, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.1394, 0.9236, 1.0000, 0.4682, 0.0000, 0.0000]], dtype=torch.float64) AF:  tensor(1.5298, dtype=torch.float64) , Y:  -0.8347940131033184 , Y grad GP:  tensor([-5.2992e+00,  1.7199e+00,  2.7197e-03, -3.4114e+00, -7.1940e-02,\n",
            "        -1.1447e+00], dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-7.5206,  0.5488,  0.0131, -1.7646, -0.0261, -0.8970])\n",
            "\n",
            " Trial: 1, Iteration: 38, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.6612, 1.0000, 1.0000, 0.2181, 0.0000, 0.0613]], dtype=torch.float64) AF:  tensor(0.9608, dtype=torch.float64) , Y:  -0.2615877771829719 , Y grad GP:  tensor([ 6.8307,  1.0483, -0.0222, -2.0971,  0.0365,  0.7892],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 2.2763,  0.4931,  0.0050, -1.8591, -0.0130,  0.1623])\n",
            "\n",
            " Trial: 1, Iteration: 39, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.6131, 0.6494, 0.0000, 0.5270, 0.0000, 0.2802]], dtype=torch.float64) AF:  tensor(1.0709, dtype=torch.float64) , Y:  -0.43265897421068406 , Y grad GP:  tensor([ 4.3926, -2.8125, -0.1756, -0.8155, -0.3062,  4.7505],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 2.9513, -1.4461, -0.0638, -0.2765, -0.2491,  2.6310])\n",
            "\n",
            " Trial: 1, Iteration: 40, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.5056, 1.0000, 0.3494, 0.8775, 0.0000, 0.1008]], dtype=torch.float64) AF:  tensor(1.3322, dtype=torch.float64) , Y:  -0.8971264364594367 , Y grad GP:  tensor([ 4.7814e+00,  2.1254e+00, -7.1697e-02,  4.0945e+00, -2.5572e-03,\n",
            "         2.8962e+00], dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 3.0721,  1.6816, -0.0473,  5.4378, -0.0207,  1.5721])\n",
            "\n",
            " Trial: 1, Iteration: 41, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.2800, 0.7721, 0.9055, 0.3345, 0.0000, 0.2395]], dtype=torch.float64) AF:  tensor(1.2240, dtype=torch.float64) , Y:  -0.7331663496170602 , Y grad GP:  tensor([-5.2005, -2.2706, -0.1106, -3.1458, -0.1935,  4.4484],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-2.9886, -1.1515,  0.0756, -3.3729, -0.2436,  3.8334])\n",
            "\n",
            " Trial: 1, Iteration: 42, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.6497, 1.0000, 0.0000, 0.8317, 0.0000, 0.0000]], dtype=torch.float64) AF:  tensor(0.9271, dtype=torch.float64) , Y:  -0.5018721636969706 , Y grad GP:  tensor([ 5.2506,  1.0889, -0.1080,  4.0525, -0.0202, -1.2134],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 4.1789,  0.9406, -0.0439,  2.5819, -0.0113, -0.5350])\n",
            "\n",
            " Trial: 1, Iteration: 43, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.3199, 0.8253, 0.8197, 0.9142, 0.2610, 0.0000]], dtype=torch.float64) AF:  tensor(1.3421, dtype=torch.float64) , Y:  -0.8495757450828345 , Y grad GP:  tensor([-3.4315, -1.7058, -0.0191,  4.3507,  0.0899, -1.1159],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-2.4448e+00, -7.7940e-01, -3.0675e-03,  5.7746e+00,  2.5217e-02,\n",
            "        -9.0828e-01])\n",
            "\n",
            " Trial: 1, Iteration: 44, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.3924, 0.8188, 0.1185, 0.6552, 1.0000, 0.3653]], dtype=torch.float64) AF:  tensor(0.9807, dtype=torch.float64) , Y:  -0.581147537094008 , Y grad GP:  tensor([-1.1743, -0.9554, -0.0809,  2.3448,  0.1067,  4.7230],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.2380, -0.5908, -0.0560,  0.9417,  0.1043,  5.3133])\n",
            "\n",
            " Trial: 1, Iteration: 45, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.5535, 1.0000, 1.0000, 0.3284, 0.0000, 0.1278]], dtype=torch.float64) AF:  tensor(1.2376, dtype=torch.float64) , Y:  -0.9600584439595767 , Y grad GP:  tensor([ 5.4357,  1.5019,  0.0090, -1.6269, -0.0257,  3.3318],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 4.8460,  1.8060,  0.0163, -4.7095, -0.0385,  2.3880])\n",
            "\n",
            " Trial: 1, Iteration: 46, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.6707, 0.7909, 1.0000, 0.7089, 0.0000, 0.0000]], dtype=torch.float64) AF:  tensor(1.0746, dtype=torch.float64) , Y:  -0.7330882282519493 , Y grad GP:  tensor([ 3.7103, -2.2884,  0.0424,  2.5305, -0.0774, -0.6352],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 6.6269, -1.0757,  0.0098,  1.9723, -0.0180, -0.7829])\n",
            "\n",
            " Trial: 1, Iteration: 47, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.6025, 0.7375, 0.5307, 0.3669, 0.0000, 0.0000]], dtype=torch.float64) AF:  tensor(1.2004, dtype=torch.float64) , Y:  -0.8832385829710311 , Y grad GP:  tensor([ 3.9105, -2.2929, -0.0264, -3.1387, -0.0188, -1.2838],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 5.9209, -2.0290, -0.0287, -3.6399, -0.0530, -0.9752])\n",
            "\n",
            " Trial: 1, Iteration: 48, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.4771, 1.0000, 1.0000, 0.3886, 0.4147, 0.3462]], dtype=torch.float64) AF:  tensor(0.9549, dtype=torch.float64) , Y:  -0.5184047203046969 , Y grad GP:  tensor([ 3.0767,  1.5597,  0.0916, -2.9927, -0.0514,  4.5180],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.2445,  1.1010,  0.0808, -1.7427,  0.1458,  4.0384])\n",
            "\n",
            " Trial: 1, Iteration: 49, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[1.0000, 0.0000, 0.0391, 0.0000, 0.3199, 0.7610]], dtype=torch.float64) AF:  tensor(0.7816, dtype=torch.float64) , Y:  -0.16411853800420667 , Y grad GP:  tensor([ 1.2648,  0.0788, -0.0575, -1.3737, -0.3584, -0.2423],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.7536, -0.1667, -0.1748, -0.9459,  0.0846,  0.2519])\n",
            "\n",
            " Trial: 1, Iteration: 50, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[1.0000, 0.2830, 0.5942, 0.0000, 0.2578, 0.3839]], dtype=torch.float64) AF:  tensor(0.7566, dtype=torch.float64) , Y:  -0.09955900157860945 , Y grad GP:  tensor([ 1.2915,  0.1271, -0.1231, -1.1411, -0.4612, -0.3499],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.4528,  0.0905,  0.0684, -0.5639, -0.1523, -0.4669])\n",
            "\n",
            " Trial: 1, Iteration: 51, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.5081, 1.0000, 0.2292, 0.8267, 0.9356, 0.3413]], dtype=torch.float64) AF:  tensor(0.8130, dtype=torch.float64) , Y:  -0.31947710449483613 , Y grad GP:  tensor([3.3931, 1.0648, 0.0337, 3.5850, 0.3371, 4.5429], dtype=torch.float64,\n",
            "       grad_fn=<MulBackward0>) , Y grad query:  tensor([ 1.1228,  0.5996, -0.0238,  1.6121,  0.0530,  2.7083])\n",
            "\n",
            " Trial: 1, Iteration: 52, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.2643, 1.0000, 0.8658, 0.8477, 0.0000, 0.2624]], dtype=torch.float64) AF:  tensor(0.9124, dtype=torch.float64) , Y:  -0.4804591049603729 , Y grad GP:  tensor([-4.5517,  1.7403,  0.0506,  4.1745, -0.0709,  4.4341],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-2.2861e+00,  9.0271e-01,  2.8433e-03,  2.6275e+00, -1.4964e-02,\n",
            "         3.0071e+00])\n",
            "\n",
            " Trial: 1, Iteration: 53, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.5479, 0.7000, 0.0535, 0.7827, 0.1595, 0.2533]], dtype=torch.float64) AF:  tensor(0.9412, dtype=torch.float64) , Y:  -0.5761503388188289 , Y grad GP:  tensor([ 3.5714, -2.1282, -0.0836,  2.9287, -0.2035,  3.7758],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 2.7716, -1.6140, -0.0572,  2.4587, -0.0447,  3.3394])\n",
            "\n",
            " Trial: 1, Iteration: 54, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/botorch/optim/optimize.py:369: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
            "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
            "Trying again with a new set of initial conditions.\n",
            "  warnings.warn(first_warn_msg, RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best value:  -3.1934105118549 , X:  tensor([[0.2996, 0.4345, 1.0000, 0.3337, 0.1537, 0.0000]], dtype=torch.float64) AF:  tensor(0.7623, dtype=torch.float64) , Y:  -0.3130583664455722 , Y grad GP:  tensor([-1.5195, -2.9814,  0.0340, -3.6029,  0.0315, -0.7227],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-1.0311, -2.0491,  0.0564, -1.3825, -0.1057, -0.5378])\n",
            "\n",
            " Trial: 1, Iteration: 55, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/botorch/optim/optimize.py:369: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
            "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
            "Trying again with a new set of initial conditions.\n",
            "  warnings.warn(first_warn_msg, RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best value:  -3.1934105118549 , X:  tensor([[0.9073, 0.2858, 0.3650, 0.3069, 0.0195, 0.7088]], dtype=torch.float64) AF:  tensor(0.7401, dtype=torch.float64) , Y:  -0.18499224044554904 , Y grad GP:  tensor([ 1.4431,  0.2115, -0.0255, -0.9160, -0.4689, -0.2915],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.7207,  0.1563, -0.1095,  0.0662, -1.7304,  0.0657])\n",
            "\n",
            " Trial: 1, Iteration: 56, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.1202, 1.0000, 0.8631, 0.7991, 1.0000, 0.0000]], dtype=torch.float64) AF:  tensor(0.7828, dtype=torch.float64) , Y:  -0.39584245026783155 , Y grad GP:  tensor([-4.6312,  1.5919, -0.0698,  2.7101, -0.1360, -0.5786],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-3.8262e+00,  7.4228e-01,  1.4211e-03,  1.7785e+00,  7.0603e-02,\n",
            "        -4.2316e-01])\n",
            "\n",
            " Trial: 1, Iteration: 57, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.7587, 0.2292, 0.9217, 0.0000, 0.8515, 0.6482]], dtype=torch.float64) AF:  tensor(0.7263, dtype=torch.float64) , Y:  -0.005360346654808395 , Y grad GP:  tensor([ 9.4441e-01,  2.2269e-01,  4.7422e-04, -1.2273e+00,  2.1510e-01,\n",
            "        -2.8350e-01], dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([ 0.0309, -0.0034,  0.0324, -0.0118,  0.0544, -0.0125])\n",
            "\n",
            " Trial: 1, Iteration: 58, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.0000, 0.0000, 0.6821, 0.8145, 0.9081, 0.5450]], dtype=torch.float64) AF:  tensor(0.6455, dtype=torch.float64) , Y:  -0.060907391132435325 , Y grad GP:  tensor([-0.2855, -0.2422, -0.1382,  0.7160,  0.6008, -0.5713],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.1594, -0.0624,  0.2578,  0.3429,  0.0217, -0.0432])\n",
            "\n",
            " Trial: 1, Iteration: 59, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.2310, 1.0000, 0.5401, 0.2909, 0.5850, 0.2307]], dtype=torch.float64) AF:  tensor(0.7729, dtype=torch.float64) , Y:  -0.4855924013097819 , Y grad GP:  tensor([-3.8042,  1.2599, -0.0323, -2.9843,  0.1615,  3.2079],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-2.5671,  1.0498, -0.0227, -2.4637,  0.1404,  2.1469])\n",
            "\n",
            " Trial: 1, Iteration: 60, Penalty: 10, Beta mean: 1.0, Beta constraint: 3.0\n",
            "Best value:  -3.1934105118549 , X:  tensor([[0.3252, 0.4191, 0.9509, 0.7080, 0.0000, 0.1625]], dtype=torch.float64) AF:  tensor(0.6997, dtype=torch.float64) , Y:  -0.35237621617472054 , Y grad GP:  tensor([-1.4623, -2.4809,  0.1459,  1.7860, -0.4436,  1.8143],\n",
            "       dtype=torch.float64, grad_fn=<MulBackward0>) , Y grad query:  tensor([-0.9282, -2.5558,  0.0219,  0.9756, -0.0687,  1.1524])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "#average values from the different trials first\n",
        "Y_all_avg = Y_all.mean(dim = 0)\n",
        "\n",
        "#give each penalty its own plot\n",
        "#each plot will have all combinations of betas\n",
        "\n",
        "for i, p in enumerate(penalty_list):\n",
        "    for j, beta_mean in enumerate(beta_mean_list):\n",
        "      fig, ax = plt.subplots(figsize=(10, 8))\n",
        "      for k, beta_constraint in enumerate(beta_constraint_list):\n",
        "\n",
        "        Y_KKT_np = negate_list * Y_all_avg[i, j, k].cpu().numpy()\n",
        "\n",
        "        if negate_list < 0:\n",
        "          ax.plot(np.minimum.accumulate(Y_KKT_np), lw = 2, label=f\"Beta constraint = {beta_constraint}\")\n",
        "        elif negate_list > 0:\n",
        "          ax.plot(np.maximum.accumulate(Y_KKT_np), lw = 2, label=f\"Beta constraint = {beta_constraint}\")\n",
        "\n",
        "        ax.grid(True)\n",
        "        ax.set_title(f\"{name_list}, D = {dim_list}, Penalty = {p}, Beta mean = {beta_mean}\", fontsize=20)\n",
        "        ax.set_xlabel(\"Number of evaluations\", fontsize=15)\n",
        "        ax.set_xlim([0, len(Y_KKT_np)])\n",
        "        ax.set_ylabel(\"Best value found\", fontsize=10)\n",
        "        ax.set_ylim([plot_bounds[0], plot_bounds[1]])\n",
        "      ax.plot([0, len(Y_KKT_np)], [objective_list, objective_list], \"--\", c=\"g\", lw=3, label=\"Optimum\")\n",
        "      ax.legend(fontsize=15, loc = \"upper right\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6UJpzprCpNju",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4771192d-4a7e-4ea1-ea7d-1401a0cd8b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}